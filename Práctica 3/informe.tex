\documentclass[11pt,leqno]{article}
\usepackage[spanish,activeacute]{babel}
\usepackage[utf8]{inputenc}
\usepackage{etex}
\usepackage{amsfonts}
\usepackage{enumerate}
\usepackage{listings}
\usepackage{amsthm}
\usepackage[hidelinks]{hyperref}
\usepackage{booktabs}
\usepackage{siunitx}
\usepackage{pgfplotstable}
\pgfplotsset{compat=1.12}
\usepackage{verbatim}
\usepackage{geometry}
\usepackage{changepage}
\usepackage{pgfplots}
\usepackage{float}
\usepgfplotslibrary{colorbrewer}

% Título y autor
\author{Jacinto Carrasco Castillo 	\\
		N.I.F. 32056356-Z			\\ 
		\href{jacintocc@correo.ugr.es}{jacintocc@correo.ugr.es}}
		
\title{	Práctica 3 Metaheurísticas.\\
		Algoritmos Genéticos para el problema \\
		de la selección de características}

% Comando para mostrar una tabla de resultados.
%    - El argumento se corresponde con la tabla
\newcommand{\maketable}[1]{
\begin{adjustwidth}{-1cm}{}
\resizebox{\linewidth}{!}{
\pgfplotstabletypeset[
	every head row/.style={
		before row={%
				\hline
				& \multicolumn{4}{c|}{WDBC} & \multicolumn{4}{c|}{Movement Libras} & \multicolumn{4}{c|}{Arrhythmia}\\
				\cline{2-13}
		},
		after row=\cline{2-13}\hline,
		column type=c
	},
	every first column/.style={ column type/.add={|}{} },
	every last row/.style={ after row=\hline},
	every row no 10/.style={before row=\hline\hline},
	column type/.add={}{|},
	columns/partition/.style={column name = , string type},
	columns/in/.style={column name =\%Clas. in},
	columns/inL/.style={column name =\%Clas. in},	
	columns/inA/.style={column name =\%Clas. in},
	columns/out/.style={column name =\%Clas. out},
	columns/outL/.style={column name =\%Clas. out},	
	columns/outA/.style={column name =\%Clas. out},
	columns/T/.style={column name =T},
	columns/tA/.style={column name =T},
	columns/tL/.style={column name =T},
	columns/red./.style={column name =\%red.},
	columns/redL/.style={column name =\%red.},	
	columns/redA/.style={column name =\%red.},
	precision=4
	]{#1}
}
\end{adjustwidth}
}

% Comando para formar una tabla que reúna en una tabla
% los resultados de las tres BD.
% Argumentos:
%  - Tabla formada
%  - Tabla WDBC
%  - Tabla Libras
%  - Tabla Arrhythmia
\newcommand{\makeresume}[4]{
\pgfplotstablevertcat{#1}{#2}
\pgfplotstablecreatecol[copy column from table={#3}{in}]{inL} {#1}
\pgfplotstablecreatecol[copy column from table={#3}{out}]{outL} {#1}
\pgfplotstablecreatecol[copy column from table={#3}{red}]{redL} {#1}
\pgfplotstablecreatecol[copy column from table={#3}{T}]{tL} {#1}
\pgfplotstablecreatecol[copy column from table={#4}{in}]{inA} {#1}
\pgfplotstablecreatecol[copy column from table={#4}{out}]{outA} {#1}
\pgfplotstablecreatecol[copy column from table={#4}{red}]{redA} {#1}
\pgfplotstablecreatecol[copy column from table={#4}{T}]{tA} {#1}
}

% Método para obtener un elemento de una tabla
% Argumentos:
%  - Tabla
%  - Fila
%  - Columna
\newcommand{\getElement}[3]{\pgfplotstablegetelem{#2}{#3}\of{#1} \pgfplotsretval}

%Definición estilo en pseudocódigo
\lstset{language=C,
		otherkeywords={FOR,BEG,IN,WHILE,IF,NOT,END,THEN,ELSE,EXIT,DO,RETURN,REPEAT},
        basicstyle=\ttfamily\footnotesize,
        keywordstyle=\color{blue}\bfseries,
        stringstyle=\color{blue}\ttfamily,
        frame=L,
  		xleftmargin=\parindent,
        commentstyle=\color{green}\ttfamily,
        breaklines=true
}

\begin{document}

% Tablas KNN
\pgfplotstableread[col sep=comma]{Software/Resultados/wKNN.csv}\datawKNN
\pgfplotstableread[col sep=comma]{Software/Resultados/lKNN.csv}\datalKNN
\pgfplotstableread[col sep=comma]{Software/Resultados/aKNN.csv}\dataaKNN
   
% Tablas Greedy SFS
\pgfplotstableread[col sep=comma]{Software/Resultados/wSFS.csv}\datawSFS
\pgfplotstableread[col sep=comma]{Software/Resultados/lSFS.csv}\datalSFS
\pgfplotstableread[col sep=comma]{Software/Resultados/aSFS.csv}\dataaSFS

% Tablas AGG
\pgfplotstableread[col sep=comma]{Software/Resultados/wAGG.csv}\datawAGG
\pgfplotstableread[col sep=comma]{Software/Resultados/lAGG.csv}\datalAGG
\pgfplotstableread[col sep=comma]{Software/Resultados/aAGG.csv}\dataaAGG

% Tablas AGE
\pgfplotstableread[col sep=comma]{Software/Resultados/wAGE.csv}\datawAGE
\pgfplotstableread[col sep=comma]{Software/Resultados/lAGE.csv}\datalAGE
\pgfplotstableread[col sep=comma]{Software/Resultados/aAGE.csv}\dataaAGE

% Tablas AGG-H
\pgfplotstableread[col sep=comma]{Software/Resultados/wAGGH.csv}\datawAGGH
\pgfplotstableread[col sep=comma]{Software/Resultados/lAGGH.csv}\datalAGGH
\pgfplotstableread[col sep=comma]{Software/Resultados/aAGGH.csv}\dataaAGGH

% Tablas AGE-H
\pgfplotstableread[col sep=comma]{Software/Resultados/wAGEH.csv}\datawAGEH
\pgfplotstableread[col sep=comma]{Software/Resultados/lAGEH.csv}\datalAGEH
\pgfplotstableread[col sep=comma]{Software/Resultados/aAGEH.csv}\dataaAGEH

% Tabla Resumen
\pgfplotstableread[col sep=comma]{Software/Resultados/results.csv}\dataGlobal


% Portada y título
\maketitle

\begin{center}
Curso 2015-2016\\

Problema de Selección de Características.\\ 

Grupo de prácticas: Viernes 17:30-19:30\\

Quinto curso del Doble Grado en Ingeniería Informática y Matemáticas.\\
\textit{ }\\
\end{center}

Algoritmos considerados:
\begin{enumerate}
\item Algoritmo Genético Generacional
\item Algoritmo Genético Estacionario
\end{enumerate}

\newpage


% Índice
\tableofcontents
\newpage

\section{Descripción del problema}

El problema que nos ocupa es un problema de clasificación. Partimos de una muestra de los objetos que queremos clasificar y su etiqueta, es decir, la clase a la que pertenece y pretendemos, en base a esta muestra, poder clasificar nuevas instancias que nos lleguen.\\
La clasificación se realizará en base a una serie de características, que nos permitan determinar si un individuo pertenece a un grupo u otro. Por tanto, tendremos individuos de una población $\Omega$ representados como un vector de características: $ \omega \in \Omega; \omega = (x_1(\omega), \dots x_n(\omega))$, donde $\omega$ es un individuo de la población y $x_i, i=1,\dots n$ son las $n$ características sobre las que se tiene información. Buscamos $f:\Omega \longrightarrow C=\{C_1, \dots, C_M\}$, donde $C=\{C_1, \dots, C_M\}$ es el conjunto de clases a las que podemos asignar los objetos.\\
El problema de clasificación está relacionado con la separabilidad de las clases en el sentido de que existirá la función $f$  anteriormente mencionada siempre que las clases sean separables, es decir, siempre que un individuo con unas mismas características pertenzcan a una misma clase. Sin embargo, si se diese que dos individuos $\omega_1, \omega_2 \in \Omega$, $(x_1(\omega_1), \dots, x_n(\omega_1))=(x_1(\omega_2), \dots, x_n(\omega_2))$ y sin embargo $f(\omega_1) \neq f(\omega_2)$, no podrá existir $f$. En todo caso, querríamos obtener la mayor tasa de acierto posible.\\  
Por tanto, tratamos, en base a unos datos, hallar la mejor $f$ posible. De esto trata el aprendizaje supervisado: Se conocen instancias de los datos y las clases a las que pertenecen. Usaremos como técnica de aprendizaje supervisado la técnica estadística conocida como $k$ vecinos más cercanos. Se trata de buscar los $k$ vecinos más cercanos y asignar al objeto la clase que predomine de entre los vecinos. En caso de empate, se seleccionará la clase con más votos más cercana.\\  
Pero no nos quedamos en el problema de clasificación, sino que buscamos reducir el número de características. Con esto pretendemos seleccionar las características que nos den un mejor resultado (por ser las más influyentes a la hora de decidir la categoría). Usaremos los datos de entrenamiento haciendo pruebas mediante diferentes metaheurísticas hasta obtener la mejor selección que seamos capaces de encontrar.\\  
El interés en realizar la selección de características reside en que se aumentará la eficiencia, al requerir menos tiempo para construir el clasificador, y que se mejoran los resultados al descartar las características menos influyentes y que sólo aportan ruido. Esto hace también que se reduzcan los costes de mantenimiento y se aumente la interpretabilidad de los datos.\\
Las funciones de evaluación pueden estar basadas en la consistencia, en la Teoría de la Información, en la distancia o en el rendimiento de clasificadores. Nosotros usaremos el rendimiento promedio de un clasificador $3-NN$.


\section{Descripción de la aplicación de los algoritmos}
\subsection{Representación de soluciones}
	Para este problema tenemos varias formas posibles de representar las soluciones:
	\begin{itemize}
		\item Representación binaria: Cada solución está representada por un vector binario de longitud igual al número de características, donde las posiciones seleccionadas tendrán un 1 o $\texttt{True}$ y las no seleccionadas un 0 o $\texttt{False}$. Esta opción, que será la que tomaremos, sólo es recomendable si no tenemos restricciones sobre el número de características seleccionadas.
		\item Representación entera: Cada solución es un vector de tamaño fijo $m \leq n$ con las características seleccionadas.
		\item Representación de orden: Cada solución es una permutación de $n$ elementos, ordenados según la importancia de cada característica.
	\end{itemize}
	En las dos últimas representaciones el espacio de soluciones es mayor que el espacio de búsqueda. Además, la representación binaria nos facilita la aplicación de los operadores de cruce o mutación, manteniendo la consistencia.\\
	Para esta práctica, aunque la representación de las soluciones también venga dada por la representación binaria, tendremos en todo momento una población en forma de \texttt{array} estructurado. Esto es, un \texttt{array} donde cada elemento está formado a su vez por dos atributos: el cromosoma, es decir, el vector de valores \textit{booleanos} que determinan la selección o no de una característica, y el valor o \textit{score} del mismo. De esta manera podemos saber la tasa de acierto de un vector solución sin tener que volver a llamar a la función de evaluación; sólo llamaremos a esta función cuando surja el nuevo individuo de la población.

\subsection{Función objetivo}
	La función objetivo será el porcentaje de acierto en el conjunto de test para el clasificador $\texttt{3-NN}$ obtenido usando las distancias de los individuos $\omega$ en las dimensiones representadas por las características seleccionadas en el vector solución para el conjunto de entrenamiento. 
	El objetivo será maximizar esta función. A la hora de buscar esta solución sólo estaremos manejando los datos de entrenamiento, luego aquí la función objetivo será la media de tasa de acierto para cada uno de los datos de entrenamiento con respecto a todos los demás, por lo que tenemos que usar la técnica de $\textit{Leave-One-Out}$. 
	Esta técnica consiste en quitar del conjunto de datos cada uno de los elementos, comprobar el acierto o no para este dato en concreto, y devolverlo al conjunto de datos. Así evitamos que los resultados estén sesgados a favor de la clase o etiqueta original, al contar siempre con un voto la clase verdadera.
	\newpage
	La implementación de la función objetivo (obtener el \textit{score} para Test) la he realizado basándome en el código paralelizado realizado para CUDA por Alejandro García Montoro para la función de $\textit{Leave One Out}$. El pseudocódigo incluido se trata del esquema seguido para cada proceso, esto es, cada elemento en el conjunto de datos de entrenamiento, puesto que el método en $\texttt{Python}$ para pasarle a la GPU los datos de entrenamiento, test, categorías y un puntero con la solución no tiene mayor interés.
	
\begin{lstlisting}[mathescape=true]
targetFunction(data_train, categories_train, 
               data_test,  categories_test):
BEGIN
   test $\leftarrow$ Get Process Number
   num_test $\leftarrow$ length(data_test)
   
   EXIT IF test > num_test
   my_features $\leftarrow$ data_test[test]
   
   k_nearest $\leftarrow$ {{item: -1, distance:$\infty$}, size = k}
	
   FOR item IN data_train
      distance $\leftarrow$ computeDistance(my_features, item)
      k_nearest $\leftarrow$ update(item, distance)
   END
	
   class $\leftarrow$ poll(classes of k_nearest)
      
   RETURN class = categories_test[test]
END
\end{lstlisting}

	Esto en \texttt{CUDA} lo que hace es guardarnos, para cada proceso, si se ha acertado o no. Posteriormente se pasa el vector con cada resultado (cada ejecución de este código) de nuevo a \texttt{Python} y se calcula el porcentaje de aciertos. Nótese que no se realiza la proyección por las características seleccionadas, esto lo hacemos al pasar los datos.\\
	Para la función de evaluación de las posibles soluciones que se van generando durante la búsqueda utilizo el método realizado por Alejandro García Montoro para usar CUDA. El algoritmo es similar al anterior, pero incluye \textit{Leave One Out}:

\newpage
\begin{lstlisting}[mathescape=true]
targetFunctionLeaveOneOut(data_train, categories_train):
BEGIN
   sample $\leftarrow$ Get Process Number
   num_samples $\leftarrow$ length(data_train)
   
   EXIT IF sample > num_samples
   my_features $\leftarrow$ data_train[sample]
   
   k_nearest $\leftarrow$ {{item: -1, distance:$\infty$}, size=k}
	
   FOR item IN data_train
    IF item $\neq$ sample THEN
      distance $\leftarrow$ computeDistance(my_features, item)
      k_nearest $\leftarrow$ update(item, distance)
   END
	
   class $\leftarrow$ poll(classes of k_nearest)
      
   RETURN class = categories_train[sample]
END
\end{lstlisting}

\subsection{Operadores comunes}
	
	Para los dos algoritmos se comparte el operador de mutación y también, en cierta medida, el operador de cruce:
	
\subsubsection{Operador de cruce}

	El operador de cruce de cada algoritmo se diferencia en que en el esquema estacionario únicamente se reproducen dos de los padres, mientras que en el esquema generacional, se seleccionan tantos padres como individuos tenga la población (se dará el caso con frecuencia de que un individuo se reproduzca más veces que otro). Sin embargo, sólo se cruzarán el $70\%$ de ellos, con lo que el operador de cruce para el caso generacional cruza únicamente el $70\%$ primero del vector de padres a cruzar, manteniendo el $30\%$ restante como estaba. 

\paragraph{Operador de cruce de dos puntos}

	El operador de cruce que se indica en la práctica para hacer es el cruce clásico en dos puntos. Para este cruce, dados dos padres tomamos dos posiciones aleatorias en dos vectores e intercambiamos la parte central, obteniendo a los hijos:
	
\begin{lstlisting}[mathescape=true]
twoPointsCrossOperator( parent_1, parent_2 ):
BEGIN
   a,b $\leftarrow$ {random{1,$\dots$,num_features-1}, size = 2,replace=False}

   desc_1 $\leftarrow$ concatenate(parent_$1_0$,$\dots$,parent_$1_{a-1}$,
                         parent_$2_a$,$\dots$,parent_$2_{b-1}$,
                         parent_$1_b$,$\dots$,parent_$1_{num\_features-1}$)
   desc_2 $\leftarrow$ concatenate(parent_$2_0$,$\dots$,parent_$2_{a-1}$,
                         parent_$1_a$,$\dots$,parent_$1_{b-1}$,
                         parent_$2_b$,$\dots$,parent_$2_{num\_features-1}$)
   RETURN desc_1, desc_2
END

\end{lstlisting}
	
\paragraph{Operador de cruce uniforme}

	He implementado también una modificación sobre el \textit{Half Cross Uniform} (HUX) consistente en, dados dos padres, asignar a cada gen del hijo el valor del gen de los padres si éste coincide en ambos; si es distinto, asignamos al gen de cada uno de los hijos los valores \texttt{True} o \texttt{False} aleatoriamente. Esto significa que, para un gen en el que los padres tienen distintos valores, un hijo (aleatoriamente en cada gen) recibirá \texttt{True} y el otro \texttt{False}. Así maximizamos la distancia \textit{hamming} entre los hijos, obteniendo mayor diversidad. 
	
\begin{lstlisting}[mathescape=true]
huxCrossOperator( parent_1, parent_2 ):
BEGIN
   FOR j IN {1,..., num_features} :
      IF parent_1[j] = parent_2[j] THEN
         desc_1[j] $\leftarrow$ parent_1[j]
         desc_2[j] $\leftarrow$ parent_1[j]
      ELSE
         gen $\leftarrow$ random({True,False})
         desc_1[j] $\leftarrow$ gen     
         desc_2[j] $\leftarrow$ not gen
   END
   
   RETURN desc_1, desc_2
END
\end{lstlisting}
	
	
\subsubsection{Operador de mutación}

	El operador de mutación se encarga de introducir diversidad en la población, favoreciendo la búsqueda en distintas zonas del espacio. Sin embargo, no podemos basar nuestra estrategia de búsqueda de buenas soluciones sólo en la mutación, pues esto nos haría explorar más zonas de búsqueda, sí, pero haciéndolo de forma aleatoria, no intensificando sobre regiones de las que se tenga información de que pueden ser buenas. Debido a esto, la probabilidad de mutación será baja, en concreto, de $0.001$ por cada gen. Para ahorrar cálculos repetitivos he descartado la opción de hacer un \texttt{random} por cada gen que se somete al operador de mutación, mutando $1$ gen seleccionado aleatoriamente por cada $1000$ genes que pasen por el método en cuestión. Además, para el resto de dividir el número de genes de la población de hijos entre $1000$ se genera un número aleatorio. Si este número es menor que el resto de la división por la probabilidad de realizar una mutación, mutaremos $1$ gen más.
	\paragraph{Ejemplo} Sea una población de $30$ individuos con $50$ características. Esto hace un total de $1500$ genes que pasarán por el proceso de mutación. $\lfloor \frac{1500}{1000} \rfloor = 1$, luego mutaremos un gen. Pero $1500 \equiv 500 mod(100)$, distinto de $0$, luego si se cumple \texttt{random()} $ < \frac{1500 mod(1000)}{1000} = 0.5$, modificamos un gen adicional.\\
	La operación para mutar un bit de un determinado individuo es la ya conocida operación \texttt{flip} que nos hacía obtener los vecinos en las prácticas anteriores:
	
\begin{lstlisting}[mathescape=true]
flip(solution, positon):
BEGIN
	neighbour $\leftarrow$ copy(solution)
	actual_value $\leftarrow$ $\texttt{solution}_{\texttt{position}}$
	$\texttt{neighbour}_{\texttt{position}}$ $\leftarrow$ NOT actual_value
	RETURN neighbour
END
\end{lstlisting}

	Por tanto, el operador de mutación nos queda de la siguiente manera: 
	
\begin{lstlisting}[mathescape=true]
mutate(descendants, mutation_prob):
BEGIN
   total_genes $\leftarrow$ length(descendants)*num_features
                                 
   num_gens_to_mutate $\leftarrow$ floor(total_genes*mutation_prob)
    
   IF random() < total_genes*mutation_prob-num_genes_to_mutate
      num_gens_to_mutate $\leftarrow$ num_gens_to_mutate +1
    
   individ $\leftarrow$ {random(descendants), size = num_gens_to_mutate}
   genes $\leftarrow$ {random({0,...,num_features-1}),size = num_gens_to_mutate}
   FOR (individ, gen) IN (individ,genes):
      individ[chromosome] $\leftarrow$ flip(individ[chromosome], gen)
      individ[score] $\leftarrow$ 0
   END
   
   RETURN descendants
END
\end{lstlisting}

	Ajustando el valor del individuo mutado nos aseguramos que si el individuo mutado pertenecía a la población (estaba en el $30\%$ de la selección de padres que no se ha cruzado) se vuelve a evaluar y nos ahorramos hacerlo si el individuo no hubiera mutado.


\subsubsection{Torneo}

Hay además una operación que se necesita para los dos esquemas y su sistema de elección, y es el torneo. Esta función se encarga de determinar cuál de dos individuos de la población es mejor y, por tanto cuál de ellos se reproducirá. En nuestro caso, entendemos que una solución es mejor que otra si tiene una mejor tasa de acierto o, en caso de tener la misma tasa de acierto, tiene seleccionadas menos características. Si se volviese a producir un empate, se devolvería uno de los dos candidatos al azar.
	
\begin{lstlisting}[mathescape=true]
tournament(p_1, p_2):
BEGIN
   IF p_1 is better than p_2 THEN
      RETURN p_1
   ELSE IF p_2 is better than p_1 THEN
      RETURN p_2
   ELSE
      RETURN random({p_1,p_2})
END
\end{lstlisting}


\section{Estructura del método de búsqueda}

En esta práctica no sólo hay diversos operadores comunes, sino que el esquema general de los algoritmos es el mismo y las diferencias están, precisamente, en operadores concretos diferentes para cada algoritmo. Presentaré en primer lugar la estructura de los algoritmos genéticos implementados y posteriormente los operadores específicos de estos algoritmos.
	
\begin{lstlisting}[mathescape=true]
geneticAlgorithm(data, categories, operators):
BEGIN
   MAX_CHECKS $\leftarrow$ 1500
   MUTATION_PROBABILITY  $\leftarrow$ 0.001
   
   chromosomes $\leftarrow$ {{random{T,F}: size = num_features }:size = 30}
   scores $\leftarrow$ {score(data[chrom],categories): chrom $\in$ chromosomes} 
   
   population $\leftarrow$ concatenate( (chromosomes, scores), by columns)
   sort(population, by scores)
   
   num_checks $\leftarrow$ 30
   
   WHILE num_checks < MAX_CHECKS DO
      selected_parents $\leftarrow$ selectionOperator(population)
      
      descendants $\leftarrow$  crossOperator(selected_parents)
      descendants $\leftarrow$ mutationOperator(descendants, MUTATION_PROBABILITY)
                                                      
      FOR desc IN descendants which are not evaluated:
         score(data[desc],categories)
         num_checks $\leftarrow$ num_checks + 1
                            
      replaceOperator(population, descendants)
      sort(population, by scores)
   END
END
\end{lstlisting}	

	Esta estructura básica hará más fácil la construcción de algoritmos evolutivos, pues sólo tendremos que modificar los operadores de selección, cruce, mutación y reemplazamiento. El funcionamiento será el visto en clase: en primer lugar se genera una población aleatoria, evaluamos y ordenamos con respecto a esta puntuación obtenida. Entonces, mientras el número de evaluaciones realizados sea menor que el máximo establecido ($15000$ en nuestro caso), se realiza el siguiente bucle:
	
\begin{enumerate}[i]
\item Se seleccionan unos padres de la población con \texttt{selectionOperator}.
\item Estos padres se reproducen mediante \texttt{crossOperator}
\item Los cromosomas obtenidos se someten a una mutación aleatoria usando \texttt{mutation}-\texttt{Operator}
\item Se evalúan los hijos.
\item Se produce un reemplazo en la generación.
\item Se reordena la población.
\end{enumerate}

	Finalmente, se devuelve el mejor individuo de la población existente al final de las evaluaciones. 

\subsection{Algoritmo Genético Generacional}

\subsubsection{Operador de selección}

	El operador de selección para el esquema generacional consiste en seleccionar aleatoriamente elementos de la población hasta obtener tantas parejas como elementos de la población y realizar el torneo entre estas parejas, quedándose con los vencedores.
	
\begin{lstlisting}[mathescape=true]
selectionOperator_generational(population):
BEGIN
   tourn_cand $\leftarrow$ {random(population): size = 2 length(population)}
   parents $\leftarrow$ {tournament(tourn_cand[i], tourn_cand[i+1]) : 
               i = 0,2,...,2*(length(population)-1)}
   
   RETURN parents
END
\end{lstlisting}

\subsubsection{Operador de reemplazamiento}

	En el operador de reemplazamiento, simplemente se intercambia la población actual por la de los descendientes, aunque como se da el elitismo, se reemplaza al peor individuo de la población de descendientes por el mejor de la población anterior si el mejor individuo de los descendientes no tuviese una mejor puntuación:
	
\begin{lstlisting}[mathescape=true]
replaceOperator_generational(population, descendants):
BEGIN
   best $\leftarrow$ first(population)
   IF best is better than best(descendants) THEN
      last(descendants) = best
   
   RETURN descendants
END
\end{lstlisting}

Para simplificar la lectura en el código y minimizar el número de operaciones, sobre todo usando los vectores de \texttt{numpy}, el orden es de menor a mayor, luego el mejor individuo se encuentra en la última posición. En el pseudocódigo se supone que los vectores están ordenados de mayor a menor tasa de aprendizaje.

\subsection{Algoritmo Genético Estacionario}

\subsubsection{Operador de selección}

El operador de selección en el esquema estacionario es el mismo que para el generacional, con la salvedad de que los padres seleccionados son únicamente 2, con lo que necesitamos 4 elementos que participen en sendos torneos.

\subsubsection{Operador de reemplazamiento}
	
	El operador de reemplazamiento sí es diferente al del esquema generacional. Al tener únicamente dos descendientes en cada iteración, no podríamos sustituir enteramente la población por la siguiente generación, sino que seleccionamos los dos individuos de la población, los comparamos con los dos descendientes generados y escogemos los dos mejores de estos cuatro elementos.
	
\begin{lstlisting}[mathescape=true]
replaceOperator_stationary(population, descendants):
BEGIN
   replacement $\leftarrow$ concatenate(last(population, size=2), descendants)
   
   sort(replacement, by 'score')
   last(population, size = 2)  $\leftarrow$ first(replacement, size = 2)
   
   RETURN population
END
\end{lstlisting}	
	
\section{Algoritmo de comparación}

Como algoritmo de comparación tenemos el algoritmo \textit{greedy} SFS. Partiendo de un vector con ninguna característica seleccionada, exploramos por el entorno y nos quedamos con el vecino que genera una mejor tasa de acierto. Repetimos este proceso hasta que ningún vecino aporta una mejora a la solución obtenida.

	\begin{lstlisting}[mathescape=true]
greedySFS(data, categories):
BEGIN
   solution $\leftarrow$ {F,...,F: size = num_features}
   current_value $\leftarrow$ getValue(data, categories, solution)
   
   REPEAT
      neighbours $\leftarrow$ {flip(solution,i): i $\in$ characteristics}
   
      best_value $\leftarrow$ $\max_{\texttt{neighbours}}$ getValue(data, categories, $\cdot$)
      
      IF best_value > current_value THEN
         solution $\leftarrow$ $argmax_{\texttt{neighbours}}$ getValue(data, categories, $\cdot$)
   
   WHILE(best_value > current_value)
   
   RETURN solution
END
	\end{lstlisting}


\section{Procedimiento para desarrollar la práctica}

El código de la práctica está realizado en $\texttt{Python 3.5.1}$ y en \texttt{CUDA}. Como se ha comentado anteriormente, el código para el KNN está paralelizado usando el código de Alejandro García Montoro para usarlo con \textit{leave-one-out} y añadiéndole un método para usarlo como función de evaluación de la solución obtenida para el conjunto de test. Esto ha permitido reducir los tiempos considerablemente.\\
Los paquetes utilizados son:
\begin{enumerate}
	\item \texttt{scipy} para leer de una manera sencilla la base de datos.
	\item \texttt{numpy} para el manejo de vectores y matrices y tratar que sea algo más eficiente en lugar de las listas de \texttt{Python}.
	\item \texttt{ctype} para importar el generador de números aleatorios en \texttt{C} disponible en la página web de la asignatura. 
	\item \texttt{csv} para la lectura y escritura de ficheros \texttt{.csv} con los que manejar más cómodamente los datos.
	\item \texttt{pycuda} y \texttt{jinja2} para la paralelización en \texttt{CUDA}.
\end{enumerate}	

	La semilla con la que he realizado las ejecuciones es $3141592$, insertada tanto en el generador en $\texttt{C}$ como en el generador de números de $\texttt{numpy}$ y en el propio de \texttt{Python}. He usado los dos porque pretendía usar el primero, que es con el que se realizan las particiones, pero al llegar a los métodos que usan los generadores de números pseudoaleatorios en su funcionamiento me dí cuenta de que tendría que repetir el código de importación del módulo en \texttt{C} para cada método, por lo que opté por usar en los métodos el \texttt{random} de \texttt{numpy}. 
	
\subsection{Ejecución del programa}
La salida de cada ejecución (10 iteraciones de un algoritmo con una base de datos) se puede elegir entre mostrar por pantalla o redirigir a un archivo $\texttt{.csv}$ para manejarlo posteriormente, por ejemplo para incluir la tabla en \LaTeX.\\
Los parámetros que acepta el programa son:
\begin{itemize}
\item Base de datos: Será una letra $\texttt{W,L,A}$ que representa cada una de las bases de datos a utilizar. Este parámetro es el único obligatorio.
\item Algoritmo utilizado: Por defecto es el KNN. Para introducir uno distinto, se usa $\texttt{-a}$ seguido de una letra entre \texttt{K,S,G,E,GH,EH} que se corresponden con KNN, \textit{greedy} SFS, algoritmo genético generacional y algoritmo genético estacionario, generacional con cruce HUX y estacionario con cruce HUX, respectivamente.
\item Semilla. Para incluir una semilla, se añade $\texttt{-seed}$ seguido del número que usaremos como semilla. Por defecto es 3141592.
\item Salida por pantalla o a fichero. Se utiliza con el parámetro opcional \texttt{-write} para escribir en un fichero en una carpeta llamada \texttt{Resultados}. El nombre del fichero será la primera letra de la base de datos utilizada seguida por las iniciales del algoritmo. Incluye también la media, el mínimo, el máximo y la desviación típica para cada columna.
\item \texttt{-h} o \texttt{--help} para mostrar la ayuda y cómo se introducen los parámetros.
\end{itemize}

Por tanto, la ejecución del programa se hará de la siguiente manera:
\[ \texttt{python Practica3.py base\_de\_datos [-a algoritmo -seed semilla -write T/F ]} \]
Si por ejemplo queremos lanzar la base de datos de \texttt{WDBC} con el AGE, semilla 123456 y que los resultados se muestren por pantalla, escribimos
\[ \texttt{python Practica3.py W -a E -seed 123456}\]
Si optamos por la base de datos \texttt{Arrhythmia} con el AGG con el cruce HUX y guardar el resultado en un fichero:
\[ \texttt{python Practica3.py A -a GH -write True}\]
Para mostrar la introducción de parámetros:
\[ \texttt{python Practica3.py --help}\]

\section{Experimentos y análisis de resultados}

\subsection{Descripción de los casos}

Los casos del problema planteados son tres, cada uno de ellos asociado a una base de datos:

\begin{itemize}
\item WDBC: Base de datos con los atributos estimados a partir de una imagen de una aspiración de una masa en la mama. Tiene 569 ejemplos, 30 atributos y debemos clasificar cada individuo en dos valores.
\item Movement Libras: Base de datos con la representación de los movimientos de la mano en el lenguaje de signos LIBRAS. Tiene 360 ejemplos y consta de 91 atributos.
\item Arrhythmia: Contiene datos de pacientes durante la presencia y ausencia de arritmia cardíaca. Tiene 386 ejemplos y 254 atributos para categorizar en 5 clases. He reducido el número de características eliminando las columnas que tuvieran el mismo valor para todos los datos. Está explicado en la práctica 2 que tardaba excesivamente en la búsqueda local si se intentaba bajar el número de características deseleccionando aquellas que no influyesen en la tasa de acierto.
\end{itemize}


\subsection{Resultados}
\subsubsection{KNN}
% Tablas Resumen KNN
\makeresume{\dataKNN}{\datawKNN}{\datalKNN}{\dataaKNN}

% Salida por pantalla
\maketable{\dataKNN}

En este caso el análisis es el mismo que en las prácticas anteriores. Con el \texttt{KNN} se ve cómo es la BD en general y qué tasas de acierto se obtiene seleccionando todas las categorías. Las diferentes iteraciones y sus resultados no son más que para particiones distintas, pues la solución es la misma para todas las ejecuciones del algoritmo. Se ve que en \texttt{WDBC} y \texttt{Arrhythmia} se obtienen porcentajes similares para la clasificación dentro de la muestra y fuera, como cabría esperar, pues las particiones se hacen equilibradamente, y sin embargo en \texttt{Libras} el porcentaje de acierto fuera de la muestra es superior. Esto se puede deber a que hay un gran número de clases y no tantos representantes de esas clases como en las dos primeras bases de datos.

\subsubsection{SFS}

% Tablas Resumen SFS
\makeresume{\dataSFS}{\datawSFS}{\datalSFS}{\dataaSFS}

% Salida por pantalla
\maketable{\dataSFS}

Para el \texttt{SFS} se obtienen buenos resultados comparándolos con el \texttt{KNN}, especialmente en \texttt{Arrhythmia}, debido a que al haber muchas características y relativamente pocas clases, seleccionando bien unas pocas características se obtienen muy buenos resultados, introduciendo ruido con otras.

\subsubsection{Algoritmo genético generacional}
% Tablas Resumen AGG
\makeresume{\dataAGG}{\datawAGG}{\datalAGG}{\dataaAGG}

% Salida por pantalla
\maketable{\dataAGG}

Los mejores resultados con respecto a los algoritmos de comparación (\texttt{KNN} y \texttt{SFS}) se obtienen en las bases de datos \texttt{WDBC} y \texttt{Libras}, en cambio en \texttt{Arrhythmia} los mejores resultados siguen siendo los del algoritmo \texttt{SFS} debido a la importancia de la reducción de características comentada en el apartado anterior. Si comparamos los resultados con los obtenidos en la práctica 2, tampoco sale bien parado pues los resultados son inferiores, especialmente en las bases de datos de mayor tamaño. Sin embargo, el tiempo en \texttt{Arrhythmia} es menor que \texttt{BMB} e \texttt{ILS} obteniendo los tres algoritmos resultados similares, con lo que cabe pensar que los resultados podrían mejorar si una parte de las evaluaciones se dedicaran a hacer búsqueda local. 

\subsubsection{Algoritmo genético estacionario}
% Tablas Resumen AGE
\makeresume{\dataAGE}{\datawAGE}{\datalAGE}{\dataaAGE}

% Salida por pantalla
\maketable{\dataAGE}

Si comparamos con los resultados del algortimo genético con el esquema generacional los resultados son similares, aunque no es así en el tiempo, siendo superior en el esquema estacionario. Esto se puede deber a que se hacen muchas reordenaciones cuando sólo se han introducido dos elementos en cada generación, por lo que podríamos pensar en cambiar el algoritmo de ordenación y también en aumentar la presión para que se introduzcan más elementos en cada generación.

\subsubsection{Algoritmo genético generacional - cruce HUX}
% Tablas Resumen AGG-H
\makeresume{\dataAGGH}{\datawAGGH}{\datalAGGH}{\dataaAGGH}

% Salida por pantalla
\maketable{\dataAGGH}

Si comparamos los resultados de este cruce con los del mismo algoritmo y esquema, pero con cruce por dos puntos, vemos que los resultados obtenidos por el cruce uniforme son mejores. Para este problema, donde lo importante es seleccionar bien qué características son las importantes, esto se realiza mejor si los hijos adquieren las características relevantes de los padres (aquellas que se repiten en ambos y que han dado buenos resultados) y tratan de distanciarse (usando la aleatoriedad y la asignación) de sus hermanos. En cambio para el cruce por dos puntos los hijos se parecen en exceso a sus padres especialemente al final, cuando hay menos diversidad.

\subsubsection{Algoritmo genético estacionario - cruce HUX}
% Tablas Resumen AGE-H
\makeresume{\dataAGEH}{\datawAGEH}{\datalAGEH}{\dataaAGEH}

% Salida por pantalla
\maketable{\dataAGEH}

En esta ocasión la diferencia al introducir el cruce uniforme es un poco mayor, también debido a que los resultados del esquema estacionario eran un poco inferiores. También hay que pensar que en este esquema se van introduciendo más lentamente nuevos hijos, con lo que tendrá mayor impacto que el cruce se haga de manera eficiente.

\subsubsection{Comparación}
 
\begin{adjustwidth}{-1cm}{}
\resizebox{\linewidth}{!}{
\pgfplotstabletypeset[
	every head row/.style={
		before row={%
				\hline
				& \multicolumn{4}{c|}{WDBC} & \multicolumn{4}{c|}{Movement Libras} & \multicolumn{4}{c|}{Arrhythmia}\\
				\cline{2-13}
		},
		after row=\cline{2-13}\hline,
		column type=c
	},
	columns={algorithm,inW,outW,redW,TW,inL,outL,redL,TL,inA,outA,redA,TA},
	every first column/.style={ column type/.add={|}{} },
	every last row/.style={after row=\hline},
	column type/.add={}{|},
	columns/algorithm/.style={column name = , string type},
	columns/inW/.style={sci,  precision=4,column name =\%Clas. in},
	columns/inL/.style={column name =\%Clas. in},	
	columns/inA/.style={column name =\%Clas. in},
	columns/outW/.style={column name =\%Clas. out},
	columns/outL/.style={column name =\%Clas. out},	
	columns/outA/.style={column name =\%Clas. out},
	columns/TW/.style={column name =T},
	columns/TA/.style={column name =T},
	columns/TL/.style={column name =T},
	columns/redW/.style={column name =\%red.},
	columns/redL/.style={column name =\%red.},	
	columns/redA/.style={column name =\%red.},
	string type
	]{\dataGlobal}
}
\end{adjustwidth}

\subsection{Análisis de los resultados}

\subsubsection{Tasa In}
\begin{center}
\begin{tikzpicture}
\begin{axis}[
    ybar,
    x=2cm,
    xtick=data,% crucial line for the xticklabels directive
    ylabel=Tasa IN,
    ymin = 50,
    legend style={at={(0.5,-0.15)},anchor=north,legend columns=-1},
    xticklabels from table={\dataGlobal}{algorithm}
    %,colorbrewer cycle list=Set1
]
\addplot table [
    x=0,
    y=inW
]{\dataGlobal};

\addplot table [
    x=0,
    y=inL
]{\dataGlobal};

\addplot  table [
    x=0,
    y=inA
]{\dataGlobal};
\legend{WDBC,Libras,Arrhythmia}
\end{axis}
\end{tikzpicture}
\end{center}

	Se aprecia una mejora de los algoritmos evolutivos sobre los algortimos de comparación, de nuevo como en la práctica 2, salvo para la base de datos \texttt{Arrhythmia}, con la salvedad de que ahora el no hay ningún algoritmo,  como estaba el \texttt{GRASP} en la práctica anterior que se le acerque. De entre los algoritmos genéticos, se observan mejores resultados para el operador de cruce uniforme, en especial en las BD mayores, donde el margen de mejora era más amplio. De los dos esquemas implementados, el generacional se muestra más efectivo, posiblemente por las razones comentadas previamente: al ir introduciendo hijos poco a poco, con una probabilidad uniforme de la selección de los padres a participar en el torneo, no estamos cambiando tanto la población en cada generación como para que el nivel general aumente.
 
\subsubsection{Tasa Out}
\begin{center}
\begin{tikzpicture}
\begin{axis}[
    ybar,
    x=2cm,
    xtick=data,% crucial line for the xticklabels directive
    ylabel=Tasa OUT,
    ymin = 40,
    legend style={at={(0.5,-0.15)},anchor=north,legend columns=-1},
    xticklabels from table={\dataGlobal}{algorithm}
]
\addplot table [
    x=0,
    y=outW
]{\dataGlobal};

\addplot table [
    x=0,
    y=outL
]{\dataGlobal};

\addplot table [
    x=0,
    y=outA
]{\dataGlobal};
\legend{WDBC,Libras,Arrhythmia}
\end{axis}
\end{tikzpicture}
\end{center}

Los resultados para la tasa fuera de la población son para los algoritmos genéticos muy parejos y las diferencias no son determinantes como para decir que un algoritmo es mejor que otro, pero sí que usando el operador de cruce uniforme, los resultados vuelven a ser un poco superiores. También para esta variable el ganador en \texttt{Arrhythmia} es el algoritmo \texttt{SFS} el que obtiene mejores resultados. En cambio para \texttt{WDBC} sí que hay diferencias a favor de los algoritmos genéticos en detrimento de \texttt{SFS}. En esto tiene mucho peso la distribución de los valores de la BD y el número de características, pues los algoritmos genéticos, que no tienen ningún mecanismo para disminuir el número de características, se ven perjudicados cuando este número es elevado y sólo hay unas pocas relevantes.

\subsubsection{Tasa reducción}
\begin{center}
\begin{tikzpicture}
\begin{axis}[
    ybar,
    x=2cm,
    xtick=data,% crucial line for the xticklabels directive
    ylabel=Tasa red.,
    ymin = 0,
    legend style={at={(0.5,-0.15)},anchor=north,legend columns=-1},
    xticklabels from table={\dataGlobal}{algorithm}
]
\addplot table [
    x=0,
    y=redW
]{\dataGlobal};

\addplot table [
    x=0,
    y=redL
]{\dataGlobal};

\addplot table [
    x=0,
    y=redA
]{\dataGlobal};
\legend{WDBC,Libras,Arrhythmia}
\end{axis}
\end{tikzpicture}
\end{center}

Con la tasa de reducción se observa que las hipótesis realizadas anteriormente son coherentes con los resultados. Los mejores resultados se obtienen con el esquema generacional y, en concreto, con el operador de cruce uniforme. Las tasas de reducción son claramente mayores en \textsl{SFS} y esto es efectivo en \texttt{Arrhythmia}, aunque no tanto en las otras bases de datos. 



\subsubsection{Tiempos}

\pgfplotstabletranspose[input colnames to=DB,columns={TW,TL,TA}]\dataTimes{\dataGlobal}

\begin{center}
\pgfplotstabletypeset[string type]\dataTimes
\end{center}


\begin{center}
\begin{tikzpicture}
\begin{axis}[
    ybar,
    ylabel=Tiempo (s),
    ymin = 0,
    legend style={at={(1.2,0.7)},anchor=north},
    symbolic x coords={TW,TL,TA},
    xticklabels={WDBC,Libras,Arrhythmia},
    xtick=data% crucial line for the xticklabels directive
]
\addplot[sharp plot,blue] 
	table [x=DB, y=2]	{\dataTimes};
\addplot[sharp plot,red] 
	table [x=DB, y=3]	{\dataTimes};
\addplot[sharp plot] 
	table [x=DB, y=4]	{\dataTimes};
\addplot[sharp plot,green] 
	table [x=DB, y=5]	{\dataTimes};
\legend{AGG,AGE,AGG-H,AGE-H}
\end{axis}
\end{tikzpicture}
\end{center}

No se han incluido los tiempos para \texttt{KNN} ni \texttt{SFS} debido a que no son relevantes con respecto a los algoritmos genéticos. Tampoco existen diferencias significativas usando distintos operadores de cruce. Lo que sí se observa es un mayor tiempo para el algoritmo genético estacionario, especialmente en \texttt{Arrythmia}. De nuevo debemos pensar en que estamos ordenando en cada iteración del bucle general una ordenación, que es efectiva cuando la nueva generación ha sufrido cambios (de un $70\%$ en el esquema generacional), pero que en el estacionario sólo introducimos dos individuos nuevos, que pueden incluso no entrar en la nueva población si fuesen peores. Además, la ordenación en este caso, debido al operador de selección, es poco efectiva en cuanto a que sólo nos sirve para tener localizados a los dos peores individuos de la población; en cambio si influyese la posición en la probabilidad de ser seleccionado para el torneo y posterior cruce, quizá los resultados mejorasen con un tiempo similar.


\section{Bibliografía}
\begin{itemize}
\item \href{http://scikit-learn.org/stable/modules/neighbors.html}{Módulo en \texttt{scikit} para KNN}
\item Para realizar las tablas en \LaTeX: \href{https://www.complang.tuwien.ac.at/doc/texlive-pictures-doc/latex/pgfplots/pgfplotstable.pdf}{Manual PGFPLOTSTABLE}
\end{itemize}
\end{document}
